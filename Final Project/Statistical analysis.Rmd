---
title: "Statistical Analysis"
author: "Santosh Cheruku, Priya Shaji"
date: "5/9/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Statistical Analysis{.tabset}

### Data


```{r , results = 'hide'}
library(tidyverse)
library(psych)
library(rpart)
library(rpart.plot)
library(party)
library(kableExtra)
```

```{r echo = T, results = 'hide'}
train <- read_tsv("https://raw.githubusercontent.com/PriyaShaji/Data607/master/Final%20Project/drugLibTrain_raw.tsv", col_names = TRUE, cols(
  X1 = col_double(),
  urlDrugName = col_character(),
  rating = col_double(),
  effectiveness = col_factor(),
  sideEffects = col_factor(),
  condition = col_factor(),
  benefitsReview = col_character(),
  sideEffectsReview = col_character(),
  commentsReview = col_character()
))

test <- read_tsv("https://raw.githubusercontent.com/PriyaShaji/Data607/master/Final%20Project/drugLibTest_raw.tsv", col_names = TRUE, cols(
  X1 = col_double(),
  urlDrugName = col_character(),
  rating = col_double(),
  effectiveness = col_factor(),
  sideEffects = col_factor(),
  condition = col_factor(),
  benefitsReview = col_character(),
  sideEffectsReview = col_character(),
  commentsReview = col_character()
))

dataset <- full_join(train, test)
```

### Statistical inference


<strong> Calculate Confidence Interval </strong>

Given a patient claim that a drug is ‘Extremely Effective’, with a 95% confidence calculate the probability of a drug having ‘No SideEffect’
 
```{r}
highlyEffectiveDrugs <- subset(dataset, effectiveness=="Highly Effective")
meanRating <- mean(highlyEffectiveDrugs$rating)
sdRating <- sd(highlyEffectiveDrugs$rating)
noSideEffectDrugs <- subset(highlyEffectiveDrugs, sideEffects=='No Side Effects')

p<- nrow(noSideEffectDrugs)/nrow(highlyEffectiveDrugs)
n <- nrow(highlyEffectiveDrugs)


SE<- sqrt(p * (1-p)/n)

CILower <- p - 1.96 * SE
CIUpper <- p + 1.96 * SE

```


<strong>Kruskal Wallis One way analysis of variance</strong>

It is a non-parametric equivalent to the one way analysis of variance


```{r include=FALSE}
dataset$effectiveness <- factor(dataset$effectiveness, levels=c('Ineffective','Marginally Effective','Moderately Effective','Considerably Effective','Highly Effective'))
```


H0= An extremely effective drug means a high rated drug

H1= An extremely effective drug is not necessarily a high rated drug

```{r}
kruskal.test(dataset$rating~dataset$effectiveness)
```


Since ,p-value is less than 0.05, we reject the null hypothesis.
Therefore an extremely effective drug is not necessarily a high rated drug.


Following rejection of Kruskal wallis test, we will conduct "post hoc" procedure


<strong> Dunn test for multiple comparisons </strong> 

Since the Kruskal–Wallis test is significant, a post-hoc analysis can be performed to determine which levels of the independent variable differ from each other level.  Probably the most popular test for this is the Dunn test, which is performed with the dunnTest function in the FSA package.  Adjustments to the p-values could be made using the method option to control the familywise error rate or to control the false discovery rate. 

The Dunn test is appropriate for groups with unequal numbers of observations.



```{r}
### Dunn test

library(FSA)

drug.dunn = dunnTest(dataset$rating ~ dataset$effectiveness,
             
              method="bonferroni")

drug.dunn
```


Since our dataset has several values to compare, it can be beneficial to have R convert this table to a compact letter display for you.  The cldList function in the rcompanion package can do this.

```{r include=FALSE}
drug.dunn = drug.dunn$res

drug.dunn
```


```{r}
library(rcompanion)

cldList(comparison = drug.dunn$Comparison,
        p.value    = drug.dunn$P.adj,
        threshold  = 0.05)

```

As we see, all the 5 levels of effectiveness have different letters, therefore, they are significant and independent of each other.

<strong> Pairwise Mann–Whitney U-tests </strong>

Another post-hoc approach is to use pairwise Mann–Whitney U-tests.
Mann–Whitney U-tests is also called the Wilcoxon Rank-Sum Test. To Calculate pairwise comparisons between group levels with corrections for multiple testing.


To prevent the inflation of type I error rates, adjustments to the p-values can be made using the p.adjust.method option to control the familywise error rate or to control the false discovery rate.

If there are several values to compare, it can be beneficial to have R convert this table to a compact letter display for you.  The multcompLetters function in the multcompView package can do this, but first the table of p-values must be converted to a full table.



```{r}
drug.wilcox = pairwise.wilcox.test(dataset$rating,
                          dataset$effectiveness,
                          p.adjust.method="none")
drug.wilcox
```


```{r}
drug.wilcox = drug.wilcox$p.value

library(rcompanion)

drug.wilcox.table = fullPTable(drug.wilcox)

drug.wilcox.table

```




```{r}
library(multcompView)

multcompLetters(drug.wilcox.table, 
                compare="<", 
                threshold=0.05,
                Letters=letters,
                reversed = FALSE)
```


Values not sharing the same letter are significantly different. In this case , all the levels of effectiveness are significantly different.